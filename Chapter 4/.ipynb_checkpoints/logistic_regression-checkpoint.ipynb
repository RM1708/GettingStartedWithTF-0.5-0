{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "__mnist__ is of type base.Datasets. __Datasets__ are namedtuples (See https://docs.python.org/3.6/library/collections.html#collections.namedtuple). \n",
    "\n",
    "Datasets are __defined__ in /home/rm/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py. Datasets contain three objects of type __mnist.DataSet__.\n",
    "\n",
    "The __class DataSet__ is defined in /home/rm/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py.\n",
    "\n",
    "The class Dataset has the following __properties & methods__ that are used in the code below.\n",
    "> the property: num_examples\n",
    "> the method: next_batch()\n",
    "\n",
    "For code that illustrates the above, see the set of print() statements in MNIST-mod1.ipynb\n",
    "\n",
    "## Change to code\n",
    "mnist.Datasets are no longer to be used. The training, validation, and test data will now be read in differently. So the functionality provided by mnist.Datasets have to be replicated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyfilepath = \"/home/rm/Code-GettingStartedWithTF/Chapter 4\"\n",
    "dirname, basename = os.path.split(pyfilepath) # \n",
    "\n",
    "sys.path.append(dirname)\n",
    "#See https://gist.github.com/DCAL12/1a872bd63bedfb7b12612c8a7ec0f52e#file-notebook_importing-py\n",
    "from nbextensions import notebook_importing\n",
    "from modGetMNIST_Data_Labels import fnGetCompleteListOfTraining_Data_Labels\n",
    "from modGetMNIST_Data_Labels import fnGetCompleteListOfTest_Data_Labels\n",
    "sys.path.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "display_step = 1\n",
    "######################\n",
    "#RM\n",
    "H_IN_PIXELS = 28\n",
    "W_IN_PIXELS = 28\n",
    "INPUT_SHAPE = [None, H_IN_PIXELS * W_IN_PIXELS] #Shape of Input data\n",
    "OUTPUT_SHAPE = [None, 10] #Shape of Labels\n",
    "BATCH_SIZE = 100\n",
    "#######################\n",
    "# See \"Wrapping all together -> Switch between train and test set using Initializable iterator\"\n",
    "# in Tensorflow-Dataset-Tutorial/dataset_tutorial.ipynb\n",
    "#\n",
    "# create a placeholder to dynamically switch between batch sizes\n",
    "batch_size = tf.placeholder(tf.int64)\n",
    "\n",
    "x, y = tf.placeholder(tf.float32, shape=INPUT_SHAPE), \\\n",
    "                tf.placeholder(tf.int8, shape=OUTPUT_SHAPE)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size).repeat()\n",
    "\n",
    "iter = dataset.make_initializable_iterator()\n",
    "BatchOfFeatures_Labels = iter.get_next()\n",
    "\n",
    "####################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([H_IN_PIXELS * W_IN_PIXELS, 10]), \"Weights\")\n",
    "b = tf.Variable(tf.zeros([10]), \"Bias\")\n",
    "\n",
    "Features = tf.placeholder(tf.float32, shape=INPUT_SHAPE)\n",
    "TrueLabels = tf.placeholder(tf.float32, shape=OUTPUT_SHAPE)\n",
    "\n",
    "# Construct model\n",
    "WeightedInput = tf.matmul(Features, W)\n",
    "estimated_label = WeightedInput + b # Softmax\n",
    "activation = tf.nn.softmax(estimated_label) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cross_entropy = TrueLabels*tf.log(activation)\n",
    "cost = tf.reduce_mean\\\n",
    "       (-tf.reduce_sum\\\n",
    "        (cross_entropy,reduction_indices=1))\n",
    "\n",
    "optimizer = tf.train.\\\n",
    "            GradientDescentOptimizer(learning_rate).minimize(cost) \n",
    "\n",
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(activation, 1), \\\n",
    "                              tf.argmax(TrueLabels, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# Initializing the variables\n",
    "init_vars = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot settings\n",
    "avg_set = []\n",
    "epoch_set=[]\n",
    "\n",
    "#Read the complete MNIST training data file\n",
    "training_images, training_labels, no_of_training_images = fnGetCompleteListOfTraining_Data_Labels()\n",
    "\n",
    "#print(\"training_images.shape, before flattening: \", training_images.shape)\n",
    "assert(60000 == no_of_training_images)\n",
    "assert(training_images.shape == (no_of_training_images, H_IN_PIXELS, W_IN_PIXELS, 1))\n",
    "training_images = training_images.reshape(no_of_training_images, 28 * 28)\n",
    "#print(\"training_images.shape after flattening: \", training_images.shape)\n",
    "assert(training_images.shape == (no_of_training_images, H_IN_PIXELS * W_IN_PIXELS))\n",
    "assert(training_labels.shape == (no_of_training_images, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block is just for probing\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # initialise iterator with train data\n",
    "    #See https://www.tensorflow.org/api_docs/python/tf/data/Dataset#make_initializable_iterator\n",
    "    # The initializer property returns the tf.operation that is run. It will initialize the iterator.\n",
    "    # See https://www.tensorflow.org/api_docs/python/tf/data/Iterator#initializer\n",
    "    sess.run(iter.initializer, feed_dict={ x: training_images, \\\n",
    "                                          y: training_labels, \\\n",
    "                                          batch_size: BATCH_SIZE})\n",
    "\n",
    "    ListOfFeatures_Labels = sess.run(iter.get_next())\n",
    "    assert( ListOfFeatures_Labels[0].shape == (BATCH_SIZE, H_IN_PIXELS*W_IN_PIXELS))\n",
    "    assert( ListOfFeatures_Labels[1].shape == (BATCH_SIZE, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_vars)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_no_of_batches = no_of_training_images//BATCH_SIZE\n",
    "######################################\n",
    "        # initialise iterator with train data\n",
    "        sess.run(iter.initializer, feed_dict={ x: training_images,\\\n",
    "                                              y: training_labels, \\\n",
    "                                              batch_size: BATCH_SIZE})\n",
    "######################################\n",
    "        # Loop over all batches\n",
    "        for batch_no in range(total_no_of_batches):\n",
    "            #if(0 == batch_no):\n",
    "            #    print(\"Epoch No: {}, Batch No:{}\".format(epoch, batch_no))\n",
    "            ListOfFeatures_Labels = sess.run(BatchOfFeatures_Labels)\n",
    "            batch_Features = ListOfFeatures_Labels[0]\n",
    "            batch_Labels = ListOfFeatures_Labels[1]\n",
    "\n",
    "            assert(batch_Features.shape == (BATCH_SIZE, H_IN_PIXELS * W_IN_PIXELS))\n",
    "\n",
    "            # Fit training using batch data\n",
    "            sess.run(optimizer, \\\n",
    "                     feed_dict={Features: batch_Features, \\\n",
    "                               TrueLabels: batch_Labels})\n",
    "            # Compute average loss\n",
    "            avg_cost += (sess.run(cost, \\\n",
    "                                 feed_dict={Features: batch_Features, \\\n",
    "                                           TrueLabels: batch_Labels}) \\\n",
    "                                )/total_no_of_batches\n",
    "        # Display logs per epoch step\n",
    "        if epoch % (4) == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "        avg_set.append(avg_cost)\n",
    "        epoch_set.append(epoch+1)\n",
    "        \n",
    "    #Plot it\n",
    "    plt.plot(epoch_set,avg_set, 'o', label='Logistic Regression Training phase')\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print (\"\\nDONE: Training phase\")\n",
    "\n",
    "    print (\"Model accuracy (with Training Data):\", accuracy.eval({Features: training_images, \\\n",
    "                                          TrueLabels: training_labels}))\n",
    "\n",
    "    #Check accuracy using test data\n",
    "    test_images, test_labels, no_of_test_images = fnGetCompleteListOfTest_Data_Labels()\n",
    "\n",
    "    assert(10000 == no_of_test_images)\n",
    "    assert(test_images.shape == (no_of_test_images, H_IN_PIXELS, W_IN_PIXELS, 1))\n",
    "\n",
    "    test_images = test_images.reshape(no_of_test_images, 28 * 28)\n",
    "\n",
    "    assert(test_images.shape == (no_of_test_images, H_IN_PIXELS * W_IN_PIXELS))\n",
    "    assert(test_labels.shape == (no_of_test_images, 10))\n",
    "\n",
    "    print (\"Model accuracy (with Test Data):\", accuracy.eval({Features: test_images, \\\n",
    "                                          TrueLabels: test_labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
