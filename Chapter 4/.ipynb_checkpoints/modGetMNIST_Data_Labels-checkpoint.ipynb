{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnGetCompleteListOfTest_Data_Labels():\n",
    "    import sys, os, importlib\n",
    "    #NOTE: Path is to the directory tf_mnist. It has the file __init.py__\n",
    "    # \"The __init__.py files are required to make Python treat the directories as containing packages\"\n",
    "    # See https://docs.python.org/3/tutorial/modules.html\n",
    "    pyfilepath = \"/home/rm/cjalmeida/tf_mnist\"\n",
    "    dirname, basename = os.path.split(pyfilepath) # \n",
    "\n",
    "    sys.path.append(dirname)\n",
    "    #See https://gist.github.com/DCAL12/1a872bd63bedfb7b12612c8a7ec0f52e#file-notebook_importing-py\n",
    "    from nbextensions import notebook_importing\n",
    "    #\n",
    "    #See https://github.com/DCAL12/jupynbimp. Does not appear to work\n",
    "    #import jupynbimp \n",
    "    from tf_mnist import data as module_read_data\n",
    "    sys.path.pop()\n",
    "\n",
    "    BATCH_SIZE = 10\n",
    "    get_test_dataset = module_read_data.create_mnist_dataset(BATCH_SIZE, 'val')\n",
    "\n",
    "    test_ds = get_test_dataset[0]\n",
    "    test_size = get_test_dataset[1]\n",
    "\n",
    "    iterator: tf.data.Iterator = tf.data.Iterator.from_structure(test_ds.output_types, test_ds.output_shapes)\n",
    "    initialize_iterator_for_test = iterator.make_initializer(test_ds)\n",
    "\n",
    "    get_next_test_batch = iterator.get_next()\n",
    "\n",
    "    NoOfBatches = test_size//BATCH_SIZE\n",
    "\n",
    "    image_batch = []\n",
    "    label_batch = []\n",
    "    \n",
    "    PRINT_DEBUG = False\n",
    "    if(PRINT_DEBUG):\n",
    "        print(\"test_ds: \",test_ds)\n",
    "        print(\"\\ntest_ds.output_types: \", test_ds.output_types); \n",
    "        print(\"test_ds.output_shapes\", test_ds.output_shapes, \"\\n\")\n",
    "        print(\"test_size: \", test_size)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        image_batch.clear()\n",
    "        label_batch.clear()\n",
    "\n",
    "        sess.run(initialize_iterator_for_test)\n",
    "        for i in range(NoOfBatches):\n",
    "            test_batch = sess.run(get_next_test_batch)\n",
    "            if(5 > i):\n",
    "                if(PRINT_DEBUG):\n",
    "                    try:\n",
    "                        image_batch = test_batch[BATCH_SIZE]\n",
    "                    except:\n",
    "                        print(\"EXCEPTION: Attempt to read 1 more batch than number of batches in image_batch\")\n",
    "                    print(\"i: \", i)\n",
    "                    print(\"image_batch.shape: \", test_batch[0].shape)\n",
    "                    #print(\"image_batch[0]: \", test_batch[0][0])\n",
    "                    print(\"label_batch.shape: \", test_batch[1].shape)\n",
    "                    print(\"label_batch[0]: \", test_batch[1][0])\n",
    "                    #print(\"First image: \", test_batch[0][0])\n",
    "                    print(\"First label: \", test_batch[1][0])\n",
    "                image_batch.append(test_batch[0])\n",
    "                label_batch.append(test_batch[1])\n",
    "            else:\n",
    "                image_batch.append(test_batch[0])\n",
    "                label_batch.append(test_batch[1])\n",
    "\n",
    "        image_batch = (np.asarray(image_batch))\n",
    "        if(PRINT_DEBUG):\n",
    "            print(\"image_batch.shape[1]: \", image_batch.shape[1])\n",
    "            print(\"image_batch.shape[0]: \", image_batch.shape[0])\n",
    "        image_batch = (image_batch).reshape(image_batch.shape[0] * image_batch.shape[1], 28, 28, 1)\n",
    "        label_batch = (np.asarray(label_batch))\n",
    "        label_batch = (label_batch).reshape(label_batch.shape[0] * label_batch.shape[1], 10)\n",
    "        if(PRINT_DEBUG):\n",
    "            print(\"image_batch.shape after correcting for nesting caused by batching: \", image_batch.shape)\n",
    "            #print(\"image_batch[0]: \", image_batch[0])\n",
    "            print(\"label_batch.shape after correcting for nesting caused by batching: \", label_batch.shape)\n",
    "\n",
    "    print(\"\\nDONE: fnGetCompleteListOfTest_Data_Labels\")\n",
    "    return image_batch, label_batch, test_size\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnGetCompleteListOfTraining_Data_Labels():\n",
    "    import sys, os, importlib\n",
    "    COMMENT_OUT = True\n",
    "    if(not COMMENT_OUT):\n",
    "        pyfilepath = \"/home/rm/cjalmeida/tf_mnist/data.py\"\n",
    "        dirname, basename = os.path.split(pyfilepath) # \n",
    "\n",
    "        sys.path.append(dirname)\n",
    "        module_name = os.path.splitext(basename)[0] \n",
    "        module_read_data = importlib.import_module(module_name) \n",
    "        sys.path.pop()\n",
    "    else:\n",
    "        #NOTE: Path is to the directory tf_mnist. It has the file __init.py__\n",
    "        # \"The __init__.py files are required to make Python treat the directories as containing packages\"\n",
    "        # See https://docs.python.org/3/tutorial/modules.html\n",
    "        pyfilepath = \"/home/rm/cjalmeida/tf_mnist\"\n",
    "        dirname, basename = os.path.split(pyfilepath) # \n",
    "\n",
    "        sys.path.append(dirname)\n",
    "        #See https://gist.github.com/DCAL12/1a872bd63bedfb7b12612c8a7ec0f52e#file-notebook_importing-py\n",
    "        from nbextensions import notebook_importing\n",
    "        #\n",
    "        #See https://github.com/DCAL12/jupynbimp. Does not appear to work\n",
    "        #import jupynbimp \n",
    "        from tf_mnist import data as module_read_data\n",
    "        sys.path.pop()\n",
    "\n",
    "    BATCH_SIZE = 600\n",
    "    get_train_dataset = module_read_data.create_mnist_dataset(BATCH_SIZE, 'train')\n",
    "\n",
    "    train_ds = get_train_dataset[0]\n",
    "    train_size = get_train_dataset[1]\n",
    "\n",
    "    iterator: tf.data.Iterator = tf.data.Iterator.from_structure(train_ds.output_types, train_ds.output_shapes)\n",
    "    initialize_iterator_for_train = iterator.make_initializer(train_ds)\n",
    "\n",
    "    get_next_training_batch = iterator.get_next()\n",
    "\n",
    "    NoOfBatches = train_size//BATCH_SIZE\n",
    "\n",
    "    image_batch = []\n",
    "    label_batch = []\n",
    "    \n",
    "    PRINT_DEBUG = False\n",
    "    if(PRINT_DEBUG):\n",
    "        print(\"train_ds: \",train_ds)\n",
    "        print(\"\\ntrain_ds.output_types: \", train_ds.output_types); \n",
    "        print(\"train_ds.output_shapes\", train_ds.output_shapes, \"\\n\")\n",
    "        print(\"train_size: \", train_size)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(initialize_iterator_for_train)\n",
    "        if(PRINT_DEBUG):\n",
    "            for i in range(NoOfBatches):\n",
    "                training_batch = sess.run(get_next_training_batch)\n",
    "                if(5 > i):\n",
    "                    try:\n",
    "                        image_batch = training_batch[BATCH_SIZE]\n",
    "                    except:\n",
    "                        print(\"EXCEPTION: Attempt to read 1 more batch than number of batches in image_batch\")\n",
    "                    print(\"i: \", i)\n",
    "                    print(\"image_batch.shape: \", training_batch[0].shape)\n",
    "                    #print(\"image_batch[0]: \", training_batch[0][0])\n",
    "                    print(\"label_batch.shape: \", training_batch[1].shape)\n",
    "                    print(\"label_batch[0]: \", training_batch[1][0])\n",
    "                    #print(\"First image: \", training_batch[0][0])\n",
    "                    print(\"First label: \", training_batch[1][0])\n",
    "                    image_batch.append(training_batch[0])\n",
    "                    label_batch.append(training_batch[1])\n",
    "                else:\n",
    "                    image_batch.append(training_batch[0])\n",
    "                    label_batch.append(training_batch[1])\n",
    "            print(\"Done reading all the batches\")\n",
    "            try:\n",
    "                training_batch = sess.run(get_next_training_batch)\n",
    "            except:\n",
    "                print(\"\\nEXCEPTION: Attempt to read beyond the ***last*** batch.\\n\")\n",
    "\n",
    "        image_batch.clear()\n",
    "        label_batch.clear()\n",
    "\n",
    "        sess.run(initialize_iterator_for_train)\n",
    "        for i in range(NoOfBatches):\n",
    "            training_batch = sess.run(get_next_training_batch)\n",
    "            if(5 > i):\n",
    "                if(PRINT_DEBUG):\n",
    "                    try:\n",
    "                        image_batch = training_batch[BATCH_SIZE]\n",
    "                    except:\n",
    "                        print(\"EXCEPTION: Attempt to read 1 more batch than number of batches in image_batch\")\n",
    "                    print(\"i: \", i)\n",
    "                    print(\"image_batch.shape: \", training_batch[0].shape)\n",
    "                    #print(\"image_batch[0]: \", training_batch[0][0])\n",
    "                    print(\"label_batch.shape: \", training_batch[1].shape)\n",
    "                    print(\"label_batch[0]: \", training_batch[1][0])\n",
    "                    #print(\"First image: \", training_batch[0][0])\n",
    "                    print(\"First label: \", training_batch[1][0])\n",
    "                image_batch.append(training_batch[0])\n",
    "                label_batch.append(training_batch[1])\n",
    "            else:\n",
    "                image_batch.append(training_batch[0])\n",
    "                label_batch.append(training_batch[1])\n",
    "        if(PRINT_DEBUG):\n",
    "            print(\"Done reading all the batches - AGAIN\")\n",
    "\n",
    "        image_batch = (np.asarray(image_batch))\n",
    "        if(PRINT_DEBUG):\n",
    "            print(\"image_batch.shape[1]: \", image_batch.shape[1])\n",
    "            print(\"image_batch.shape[0]: \", image_batch.shape[0])\n",
    "        image_batch = (image_batch).reshape(image_batch.shape[0] * image_batch.shape[1], 28, 28, 1)\n",
    "        label_batch = (np.asarray(label_batch))\n",
    "        label_batch = (label_batch).reshape(label_batch.shape[0] * label_batch.shape[1], 10)\n",
    "        if(PRINT_DEBUG):\n",
    "            print(\"image_batch.shape after correcting for nesting caused by batching: \", image_batch.shape)\n",
    "            #print(\"image_batch[0]: \", image_batch[0])\n",
    "            print(\"label_batch.shape after correcting for nesting caused by batching: \", label_batch.shape)\n",
    "\n",
    "    print(\"\\nDONE: fnGetCompleteListOfMNIST_Data_Labels\")\n",
    "    return image_batch, label_batch, train_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(__name__ == \"__main__\"):\n",
    "    #Test for Training Data\n",
    "    image_batch, label_batch, train_size =  fnGetCompleteListOfTraining_Data_Labels()\n",
    "    \n",
    "    print(\"\\nTRAIN DATA Three Sample images:\\n\")\n",
    "    index = 0\n",
    "    print(\"label_batch[{}]: {}\".format(index, np.argmax(label_batch[index])))\n",
    "    plt.imshow( np.reshape(image_batch[index], [28, 28])) \n",
    "    plt.show()\n",
    "\n",
    "    index = train_size - 1\n",
    "    print(\"label_batch[{}]: {}\".format(index, np.argmax(label_batch[index])))\n",
    "    plt.imshow( np.reshape(image_batch[index], [28, 28])) \n",
    "    plt.show()\n",
    "\n",
    "    index = train_size//2\n",
    "    print(\"label_batch[{}]: {}\".format(index, np.argmax(label_batch[index])))\n",
    "    plt.imshow( np.reshape(image_batch[index], [28, 28])) \n",
    "    plt.show()\n",
    "\n",
    "    #Check for Test Data\n",
    "    image_batch, label_batch, test_size =  fnGetCompleteListOfTest_Data_Labels()\n",
    "    \n",
    "    print(\"\\nTEST DATA Three Sample images:\\n\")\n",
    "    index = 0\n",
    "    print(\"label_batch[{}]: {}\".format(index, np.argmax(label_batch[index])))\n",
    "    plt.imshow( np.reshape(image_batch[index], [28, 28])) \n",
    "    plt.show()\n",
    "\n",
    "    index = test_size - 1\n",
    "    print(\"label_batch[{}]: {}\".format(index, np.argmax(label_batch[index])))\n",
    "    plt.imshow( np.reshape(image_batch[index], [28, 28])) \n",
    "    plt.show()\n",
    "\n",
    "    index = test_size//2\n",
    "    print(\"label_batch[{}]: {}\".format(index, np.argmax(label_batch[index])))\n",
    "    plt.imshow( np.reshape(image_batch[index], [28, 28])) \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
