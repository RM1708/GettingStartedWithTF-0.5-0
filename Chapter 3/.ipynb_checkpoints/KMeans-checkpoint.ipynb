{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defects in Kmeans.py\n",
    "1. The clusters were not adapting.\n",
    "2. vector_values = zip(x_values,y_values) is a problem when converted with tf.constant()\n",
    "3. Bunch of code above partitions = tf.dynamic_partition() are comments, not code. See ref link in the code.\n",
    "4. sess.run(centroids) appears to be spurious. It does not seem to affect the behaviour even when the initial centroids are randomly chosen\n",
    "\n",
    "\n",
    "## Lessons\n",
    "1. Tests needed to show that:\n",
    "    1.1. Adaptation is taking place.\n",
    "    1.2. That it is taking place correctly\n",
    "2. Test data needs to be ___designed___. \n",
    "3. The generation of data has been modified. See comments in the code\n",
    "4. The number of steps was originally 1000. This was too much. Just a few of steps are needed.\n",
    "5. The starting centroids have been fixed, instead of being randomy chose. These are mid way along the rectangle connecting the four points around which the data is generated. The adapted centroids are printed out at each step.\n",
    "\n",
    "## TODO\n",
    "1. Add check for how many points were mis classified.\n",
    "2. Convert the input data to True classification and then plot it.\n",
    "3. Stop loop when adaptation change becomes smaller than a defined limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_partition(x_values,y_values,assignment_values):\n",
    "    labels = []\n",
    "    colors = [\"red\",\"blue\",\"green\",\"yellow\"]\n",
    "    for i in range(len(assignment_values)):\n",
    "      labels.append(colors[(assignment_values[i])])\n",
    "    color = labels\n",
    "    df = pd.DataFrame\\\n",
    "            (dict(x =x_values,y = y_values ,color = labels ))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(df['x'], df['y'], c=df['color'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vectors = 2000\n",
    "num_clusters = 4 # needs to be 4 as the display_partition() is hardcoded for 4 colors\n",
    "n_samples_per_cluster = int(num_vectors/num_clusters) # previously hardcoded\n",
    "\n",
    "num_steps = 10\n",
    "x_values = []\n",
    "y_values = []\n",
    "vector_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE RANDOM DATA\n",
    "#Original code modified.\n",
    "#Now there are 4 clear clusters.\n",
    "#The data generated is clustered around 4 points:\n",
    "# (0.2, 0.2), (0.2, 0.8), (0.8, 0.2) & (0.8, 0.8)\n",
    "for i in range(num_vectors):\n",
    "  if np.random.random() > 0.5:\n",
    "    #x_values.append(np.random.normal(0.4, 0.7))\n",
    "    #y_values.append(np.random.normal(0.2, 0.8))\n",
    "    x_values.append(np.random.normal(0.2, 0.175))\n",
    "    x_values.append(np.random.normal(0.2, 0.175))\n",
    "    y_values.append(np.random.normal(0.2, 0.175))\n",
    "    y_values.append(np.random.normal(0.8, 0.175))\n",
    "    \n",
    "  else:\n",
    "    #x_values.append(np.random.normal(0.6, 0.4))\n",
    "    #y_values.append(np.random.normal(0.8, 0.5))\n",
    "    x_values.append(np.random.normal(0.8, 0.175))\n",
    "    x_values.append(np.random.normal(0.8, 0.175))\n",
    "    y_values.append(np.random.normal(0.8, 0.175))\n",
    "    y_values.append(np.random.normal(0.2, 0.175))\n",
    "#vector_values = zip(x_values,y_values)\n",
    "#From https://stackoverflow.com/questions/209840/map-two-lists-into-a-dictionary-in-python\n",
    "# answered Oct 16 '08 at 19:09\n",
    "#Dan Lenski\n",
    "vector_values_list = list(zip(x_values,y_values))\n",
    "\n",
    "#print(\"No Of Keys: \", len(list(vector_values_list.keys())), \" \\n\")\n",
    "#print(\"No Of Values: {} \\n\".format(len(list(vector_values_list.keys()))))\n",
    "\n",
    "#import itertools\n",
    "#print(\"First 5 dictionary items: \\n\",dict(itertools.islice(vector_values_list.items(), 5)))\n",
    "#print(\"First 5 vector_values_list tuples: \\n\",vector_values_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = tf.constant(vector_values_list)\n",
    "#print(\"Vector Values List Shape: \", np.shape(vector_values_list), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot( x_values, y_values, 'o', label =' Input Data') \n",
    "#plt.legend() \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = tf.shape(vector_values_list)[0]\n",
    "random_indices = tf.random_shuffle(tf.range(0, n_samples))\n",
    "begin = [0,] #Why is this needed to be a list? See tf.slice() below\n",
    "size = [num_clusters,] #Why a list? See usage tf.slice() below. \n",
    "                        #And https://www.tensorflow.org/api_docs/python/tf/slice\n",
    "#print(\"List of Cluster Sizes: \", size, \"Length of List: \", len(size))\n",
    "assert num_clusters == size[0]\n",
    "size[0] = num_clusters # Why is this statement needed?\n",
    "#print(\"No Of Clusters: \", size[0])\n",
    "\n",
    "sess = tf.Session()\n",
    "#vectors_list = sess.run(vectors)\n",
    "#print(\"Shape of vectors i.e tf.constant(vector_values_list): \", (vectors_list).shape)\n",
    "#print(\"No of Dims of vectors i.e tf.constant(vector_values_list): \", (vectors_list).ndim)\n",
    "#print(\"First 3 Vectors\\n\", vectors_list[0:3])\n",
    "#print(\"First 3 Vectors. after revaluation\\n\", sess.run(vectors)[0:3])\n",
    "\n",
    "#print(\"No Of Samples: \", sess.run(n_samples))\n",
    "\n",
    "indices = sess.run(random_indices)\n",
    "#print(\"Random Indices: \", indices)\n",
    "#print(\"Random Indices [0:4]: \", indices[0:4])\n",
    "\n",
    "#print(\"Vector at [indices[0:4]]\\n\", sess.run(vectors)[indices[0:4]])\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_indices = tf.slice(indices, begin, size)\n",
    "\n",
    "sess = tf.Session()\n",
    "#print(\"Centroid Indices: \", sess.run(centroid_indices))\n",
    "#print(\"Centroid Indices: \", sess.run(centroid_indices))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#centroid_vectors = tf.gather(vectors, centroid_indices)\n",
    "#Now the initial cenroid vectors have been fixed.\n",
    "#These have been chosen to be roughly midway between the sides of the rectangle joining the 4 points around\n",
    "#which the random data has been geneerated\n",
    "centroid_vectors = tf.convert_to_tensor([[0.25, 0.5], [0.5, 0.25], [0.5, 0.75], [0.75, 0.25]])\n",
    "centroids = tf.Variable(centroid_vectors)\n",
    "\n",
    "expanded_vectors = tf.expand_dims(vectors, 0)\n",
    "expanded_centroids = tf.expand_dims(centroids, 1)\n",
    "\n",
    "#init_tmp = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "#print(\"Vector at [indices[0:4]]\\n\", sess.run(vectors)[indices[0:4]])\n",
    "#print(\"Centroid Indices: \", sess.run(centroid_indices))\n",
    "#print(\"Centroid Vectors: \\n\", sess.run(vectors)[sess.run(centroid_indices)])\n",
    "##sess.run(init_tmp)\n",
    "#print(\"Centroid: \\n\", sess.run(centroids))\n",
    "#print(\"Expanded Vectors at [:,indices[0:4]]: \\n\", sess.run(expanded_vectors)[:, indices[0:4]])\n",
    "#print(\"Expanded Centroid Vectors: \\n\", sess.run(expanded_centroids))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_diffs = tf.subtract(expanded_vectors,expanded_centroids)\n",
    "euclidean_distances =   \\\n",
    "                    tf.reduce_sum(tf.square(vectors_diffs), 2)\n",
    "\n",
    "assignments = tf.to_int32(tf.argmin(euclidean_distances, 0))\n",
    "\n",
    "sess = tf.Session()\n",
    "#print(\"Shape of Mutual Diff Vectors.: \\n\", sess.run(vectors_diffs).shape)\n",
    "#print(\"Mutual Diff Vectors Between Centroid Points.: \\n\", sess.run(vectors_diffs)[:, sess.run(centroid_indices)])\n",
    "#print(\"\\nShape of Mutual Euclidean Dist Between Centroid Points: \\n\", \\\n",
    "#      sess.run(euclidean_distances).shape)\n",
    "#print(\"Mutual Euclidean Dist Between Centroid Points: \\n\", \\\n",
    "#      sess.run(euclidean_distances)[:, sess.run(centroid_indices)])\n",
    "#print(\"Assignments of The Centroid Points: \\n\", sess.run(assignments)[sess.run(centroid_indices)])\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See example in https://www.tensorflow.org/api_docs/python/tf/dynamic_partition\n",
    "#tf.dynamic_partition(\n",
    "#    data,\n",
    "#    partitions,\n",
    "#    num_partitions,\n",
    "#    name=None\n",
    "#)\n",
    "\n",
    "#data = [10, 20, 30, 40, 50]\n",
    "#partitions = [0, 0, 1, 1, 0]\n",
    "#num_partitions = 2\n",
    "#outputs[0] = [10, 20, 50]\n",
    "#outputs[1] = [30, 40]\n",
    "#\n",
    "partitions = tf.dynamic_partition(vectors, assignments, num_clusters)\n",
    "\n",
    "recompute_centroids = tf.concat(\\\n",
    "                             [tf.expand_dims\\\n",
    "                              (tf.reduce_mean(partition, 0), 0)\\\n",
    "                              for partition in partitions], \\\n",
    "                            0)\n",
    "#This node makes the processing adaptive\n",
    "update_centroids = tf.assign(centroids, recompute_centroids)\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    print(\"Partitions Shape:\\n\", np.shape(sess.run(partitions)))\n",
    "#    print(\"Partitions[0]:\\n\", sess.run(partitions)[0], \"\\n\")\n",
    "#    print(\"Partitions[num_clusters - 1]:\\n\", sess.run(partitions)[num_clusters - 1], \"\\n\")\n",
    "#    print(\"Current Centroids: \\n\", centroids.eval(), \"\\n\")\n",
    "#    print(\"Updated Centroids: \\n\", sess.run(update_centroids), \"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "try:\n",
    "    sess.run(init_op)\n",
    "    #No update happens.\n",
    "    #The pattern at the end of the loop is the same as at the start\n",
    "    #\n",
    "    #Proposed Fix\n",
    "    #Introduced the tf.assig() node above.\n",
    "    #The node updates the set of centroid vectors(points).\n",
    "    #\n",
    "    #Now there is a change between the initial clusters and the final clusters\n",
    "    factor = 2\n",
    "    for step in range(factor*num_steps):\n",
    "        #_, centroid_values, assignment_values =\\\n",
    "        #Where is centroid_values used\n",
    "        #_, _, assignment_values =\\\n",
    "        #  sess.run([update_centroids,\\\n",
    "        #            centroids,\\\n",
    "        #            assignments])\n",
    "        #Split the above for each graph node in the list. Done for clarity\n",
    "        adapted_centroids = sess.run(update_centroids)\n",
    "        \n",
    "        #This does not seem to affect the behaviour even when the \n",
    "        #initial centroids are randomly chosen\n",
    "        #\n",
    "        #sess.run(centroids) \n",
    "        \n",
    "        assignment_values = sess.run(assignments)\n",
    "        if(0 == step or (factor*num_steps - 1) == step or (0 == step % (factor * 2))):\n",
    "            print(\"Step: {}\".format(step), \"\\n\")\n",
    "            print(\"Centroids: \\n{}\\n\".format(adapted_centroids))\n",
    "            display_partition(x_values,y_values,assignment_values)\n",
    "\n",
    "    print(\"Input Data:\")\n",
    "    plt.plot(x_values,y_values, 'o', label='Input Data')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "finally:\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
